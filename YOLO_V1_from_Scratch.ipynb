{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO-V1 from Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQZhvejUaD6M"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "702QN34woQ9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "architecture_config = [\n",
        "    (7, 64, 2, 3),\n",
        "    \"M\",\n",
        "    (3, 192, 1, 1),\n",
        "    \"M\",\n",
        "    (1, 128, 1, 0),\n",
        "    (3, 256, 1, 1),\n",
        "    (1, 256, 1, 0),\n",
        "    (3, 512, 1, 1),\n",
        "    \"M\",\n",
        "    [(1, 256, 1, 0), (3, 512, 1, 1), 4],\n",
        "    (1, 512, 1, 0),\n",
        "    (3, 1024, 1, 1),\n",
        "    \"M\",\n",
        "    [(1, 512, 1, 0), (3, 1024, 1, 1), 2],\n",
        "    (3, 1024, 1, 1),\n",
        "    (3, 1024, 2, 1),\n",
        "    (3, 1024, 1, 1),\n",
        "    (3, 1024, 1, 1),\n",
        "]"
      ],
      "metadata": {
        "id": "RK1ycgiuaJmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlock(layers.Layer):\n",
        "  def __init__(self, in_channels, out_channels, **kwargs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = layers.Conv2D(out_channels, use_bias = False, **kwargs)\n",
        "    self.bn = layers.BatchNormalization()\n",
        "    self.leakyrelu = layers.LeakyReLU(0.1)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.bn(x)\n",
        "    x = self.leakyrelu(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "kdgvgzYjaeN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YoloV1(tf.keras.Model):\n",
        "  def __init__(self, in_channels = 3, **kwargs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.architecture = architecture_config\n",
        "    self.in_channels = in_channels\n",
        "\n",
        "    self.conv = self.create_conv(self.architecture)\n",
        "    self.fc = self.create_fc(**kwargs)# flattem before\n",
        "\n",
        "  def create_conv(self, architecture):\n",
        "    conv_layers = tf.keras.Sequential()\n",
        "    in_channels = self.in_channels\n",
        "\n",
        "    for x in architecture:\n",
        "      \n",
        "      if type(x) == tuple:\n",
        "        conv_layers.add(CNNBlock(in_channels, out_channels = x[1], kernel_size = x[0], strides = x[2], padding = 'same')) \n",
        "        in_channels = x[1]\n",
        "      \n",
        "      elif type(x) == str:\n",
        "        conv_layers.add(layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "      \n",
        "      elif type(x) == list:\n",
        "        conv1 = x[0]\n",
        "        conv2 = x[1]\n",
        "        num_repeats = x[2]\n",
        "\n",
        "        for _ in range(num_repeats):\n",
        "          conv_layers.add(CNNBlock(in_channels, out_channels = conv1[1], kernel_size = conv1[0], strides = conv1[2], padding = 'same'))\n",
        "          conv_layers.add(CNNBlock(in_channels, out_channels = conv2[1], kernel_size = conv2[0], strides = conv2[2], padding = 'same')) \n",
        "          in_channels = conv2[1]\n",
        "      \n",
        "      \n",
        "    return conv_layers\n",
        "\n",
        "  def create_fc(self, split_size, num_boxes, num_classes):\n",
        "    \n",
        "    S, B, C = split_size, num_boxes, num_classes\n",
        "    output_dense_units = S * S * (C + (B * 5))\n",
        "   \n",
        "    fc_layers = tf.keras.Sequential()\n",
        "\n",
        "    fc_layers.add(layers.Flatten())\n",
        "    fc_layers.add(layers.Dense(4096))\n",
        "    fc_layers.add(layers.Dropout(0.5))\n",
        "    fc_layers.add(layers.LeakyReLU(0.1))\n",
        "    fc_layers.add(layers.Dense(output_dense_units)) \n",
        "    fc_layers.add(layers.Reshape((S, S, C + (B * 5)))) # Reshaped to (batch_size, S, S, (C + (B * 5))\n",
        "    \n",
        "    return fc_layers\n",
        "\n",
        "  def call(self, x):\n",
        "\n",
        "    x = self.conv(x)\n",
        "    x = self.fc(x)    \n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "SfzWPdwqb4sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo = YoloV1(in_channels = 3, split_size = 7, num_boxes = 2, num_classes = 20)"
      ],
      "metadata": {
        "id": "8KdX5Yi4hPCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.random.uniform((2, 448, 448, 3))"
      ],
      "metadata": {
        "id": "TZ0qqJrjirZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = yolo(x)\n",
        "out.shape"
      ],
      "metadata": {
        "id": "YM518gEZPtSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277c7ba4-8f51-4baf-cd98-6c26cab69be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 7, 7, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "GIjMolKaPuTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember the Bounding Box Arguments the model outputs is [x, y, w, h], where x and y are relative to each split_cell.\n",
        "\n",
        "Most datasets have BBOX cordinates, relative to the entire image. We will change that when we generate the data."
      ],
      "metadata": {
        "id": "8hebA6cjBykI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.losses as losses\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "o3_e_TuCRaDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YoloLoss(losses.Loss):\n",
        "  def __init__(self, S = 7, B = 2, C = 20):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.mse = losses.MeanSquaredError()\n",
        "    self.S = S\n",
        "    self.B = B\n",
        "    self.C = C\n",
        "    self.lambda_noobj = 0.5\n",
        "    self.lambda_coord = 5\n",
        "\n",
        "  #################### IOU LOSS #########################\n",
        "  def compute_iou(self, boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
        "    \"\"\"\n",
        "    Calculates intersection over union\n",
        "    Parameters:\n",
        "        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
        "        boxes_labels (tensor): Correct labels of Bounding Boxes (BATCH_SIZE, 4)\n",
        "        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n",
        "    Returns:\n",
        "        tensor: Intersection over union for all examples\n",
        "    \"\"\"\n",
        "\n",
        "    if box_format == \"midpoint\":\n",
        "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
        "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
        "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
        "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
        "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
        "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
        "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
        "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
        "\n",
        "    if box_format == \"corners\":\n",
        "        box1_x1 = boxes_preds[..., 0:1]\n",
        "        box1_y1 = boxes_preds[..., 1:2]\n",
        "        box1_x2 = boxes_preds[..., 2:3]\n",
        "        box1_y2 = boxes_preds[..., 3:4]  # (N, 1)\n",
        "        box2_x1 = boxes_labels[..., 0:1]\n",
        "        box2_y1 = boxes_labels[..., 1:2]\n",
        "        box2_x2 = boxes_labels[..., 2:3]\n",
        "        box2_y2 = boxes_labels[..., 3:4]\n",
        "\n",
        "    x1 = tf.math.maximum(box1_x1, box2_x1)\n",
        "    y1 = tf.math.maximum(box1_y1, box2_y1)\n",
        "    x2 = tf.math.maximum(box1_x2, box2_x2)\n",
        "    y2 = tf.math.maximum(box1_y2, box2_y2)\n",
        "\n",
        "    \n",
        "    intersection = tf.clip_by_value((x2 - x1), 0, 1) * tf.clip_by_value((x2 - x1), 0, 1)\n",
        "\n",
        "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
        "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
        "\n",
        "    return intersection / (box1_area + box2_area - intersection + 1e-6)\n",
        "\n",
        "\n",
        "  ################ LOSS FOR BOX CORDINATES ##################\n",
        "  def compute_coordinate_loss(self, predictions, target, bestbox, exists_box):\n",
        "    \n",
        "    box_predictions = exists_box * (                #Multiplying by exists_box is like identity function, only if box_exists, we need to compute all these\n",
        "        \n",
        "        (bestbox * predictions[..., 26:30])          #This assumes we use only two boxes, might wana change this\n",
        "                \n",
        "      + ((1-bestbox)* predictions[..., 21:25])\n",
        "    )\n",
        "\n",
        "    box_targets = exists_box * target[..., 21:25]\n",
        "\n",
        "\n",
        "    x_y_box_predictions = box_predictions[...,:2]\n",
        "    x_y_box_targets = box_targets[...,:2]\n",
        "\n",
        "    epsilon = tf.fill(box_predictions[..., 2:4].shape, 1e-6)\n",
        "    w_h_box_predictions = tf.math.sign(box_predictions[..., 2:4]) * tf.math.sqrt(tf.math.abs(box_predictions[..., 2:4] + epsilon)) #small epsilon ensures the gradient of sqrt (1/sqrt) does not go to infinity incase sqrt = 0 \n",
        "    w_h_box_targets = tf.sqrt(box_targets[..., 2:4])\n",
        "\n",
        "    # Reshapes (N, S, S, 2) ----> (N*S*S, 2) and then MSE\n",
        "    x_y_coordinate_loss = self.mse(\n",
        "        \n",
        "        tf.reshape(x_y_box_predictions, (-1, x_y_box_predictions.shape[-1])),\n",
        "        tf.reshape(x_y_box_targets, (-1, x_y_box_targets.shape[-1]))\n",
        "    )\n",
        "\n",
        "    # Reshapes (N, S, S, 2) ----> (N*S*S, 2) and then MSE\n",
        "    w_h_coordinate_loss = self.mse(\n",
        "        \n",
        "        tf.reshape(w_h_box_predictions, (-1, w_h_box_predictions.shape[-1])),\n",
        "        tf.reshape(w_h_box_targets, (-1, w_h_box_targets.shape[-1]))\n",
        "    )\n",
        "\n",
        "    coordinate_loss = x_y_coordinate_loss + w_h_coordinate_loss\n",
        "\n",
        "    return coordinate_loss\n",
        "\n",
        "  \n",
        "  ################### LOSS FOR OBJECT #####################\n",
        "  def compute_object_loss(self, predictions, target, bestbox, exists_box):\n",
        "    \n",
        "    pred_box = (\n",
        "        bestbox * predictions[..., 25:26] +\n",
        "        \n",
        "        (1-bestbox) * predictions[..., 20:21]\n",
        "    )\n",
        "\n",
        "    target_pred_box = target[..., 20:21]\n",
        "\n",
        "    #(N, S, S, 1) ---> (N*S*S) for MSE Loss\n",
        "    object_loss = self.mse(\n",
        "        \n",
        "        tf.reshape(exists_box*pred_box, (-1, )),\n",
        "        tf.reshape(exists_box*target_pred_box, (-1, ))\n",
        "\n",
        "    )\n",
        "\n",
        "    return object_loss\n",
        "\n",
        "  \n",
        "  ################## LOSS FOR NO OBJECT #####################\n",
        "  def compute_no_object_loss(self, predictions, target, exists_box):\n",
        "    \n",
        "    #(N, S, S, 1) ---> (N*S*S) for MSE Loss \n",
        "    no_object_loss = self.mse(\n",
        "        \n",
        "        tf.reshape((1- exists_box)*predictions[..., 20:21], (-1, )),\n",
        "        tf.reshape((1 -exists_box)*target[..., 20:21], (-1, ))\n",
        "        \n",
        "    )\n",
        "\n",
        "    no_object_loss += self.mse(\n",
        "        \n",
        "        tf.reshape((1- exists_box)*predictions[..., 25:26], (-1, )),\n",
        "        tf.reshape((1 -exists_box)*target[..., 20:21], (-1, ))\n",
        "        \n",
        "    )\n",
        "\n",
        "    return no_object_loss\n",
        "\n",
        "  \n",
        "  ################# LOSS FOR CLASSES ##################\n",
        "  def compute_class_loss(self, predictions, target, exists_box):\n",
        "   \n",
        "    #(N, S, S, 20) ---> (N*S*S, 20) for MSE Loss\n",
        "    class_loss = self.mse(\n",
        "        \n",
        "        tf.reshape(exists_box*predictions[..., :20], (-1, predictions[..., :20].shape[-1])),\n",
        "        tf.reshape(exists_box*target[..., :20], (-1, predictions[..., :20].shape[-1]))\n",
        "    )\n",
        "\n",
        "    return class_loss\n",
        "\n",
        "\n",
        "  def call(self, target, predictions):\n",
        "\n",
        "\n",
        "    iou_b1 = self.compute_iou(predictions[...,21:25], target[...,21:25])\n",
        "    iou_b2 = self.compute_iou(predictions[...,26:30], target[...,21:25])\n",
        "    ious = tf.concat([tf.expand_dims(iou_b1, 0), tf.expand_dims(iou_b2, 0)], axis = 0)\n",
        "    \n",
        "    bestbox = tf.math.argmax(ious, axis = 0)\n",
        "    bestbox = tf.cast(bestbox, tf.float32)\n",
        "    exists_box = tf.expand_dims(target[..., 20], 3)\n",
        "\n",
        "    coordinate_loss = self.compute_coordinate_loss(predictions, target, bestbox, exists_box)\n",
        "    \n",
        "    \n",
        "    object_loss = self.compute_object_loss(predictions, target, bestbox, exists_box)\n",
        "\n",
        "    \n",
        "    no_object_loss = self.compute_no_object_loss(predictions, target, exists_box)\n",
        "\n",
        "    \n",
        "    class_loss = self.compute_class_loss(predictions, target, exists_box)\n",
        "    \n",
        "    ############ TOTAL LOSS ##############\n",
        "\n",
        "    loss = ( self.lambda_coord * coordinate_loss\n",
        "            + object_loss\n",
        "            + self.lambda_noobj * no_object_loss\n",
        "            + class_loss\n",
        "           )\n",
        "    \n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "DEKe4Zm0PtOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_loss = YoloLoss()\n",
        "\n",
        "x = tf.random.uniform((1, 7, 7, 30))\n",
        "y = tf.random.uniform((1, 7, 7, 30))\n",
        "\n",
        "yolo_loss(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLCf10SZgVaq",
        "outputId": "4602b8ea-b9cb-43f9-b5c9-70f9ba40a058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.58694303>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Generation"
      ],
      "metadata": {
        "id": "ONjzmH9qg9Rj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSV File Format - ImageName.jpg LabelTextName.txt\n",
        "\n",
        "Image Format : Standard RGB with all same size\n",
        "\n",
        "Label Format(each line in the txt represents a unique bbox) : \n",
        "index_of_target_class x_center y_center height \n",
        "width\n",
        "\n",
        "Note: These coordinates will be relative to the entire image(in most cases), and will be converted to cell wise relative coordinates in the DataGenerator."
      ],
      "metadata": {
        "id": "WE-5vL16uLxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "FNLrRU0EhSWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, csv_file, img_dir, label_dir, img_res, batch_size = 32, splitcell_size = 7, num_bbox = 2, num_classes = 20):\n",
        "        \n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.img_res = img_res\n",
        "        self.batch_size = batch_size\n",
        "        self.S = splitcell_size\n",
        "        self.B = num_bbox\n",
        "        self.C = num_classes\n",
        "    \n",
        "\n",
        "    def __len__(self):\n",
        "        \n",
        "        return int(np.floor(len(self.annotations) / self.batch_size))\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        \n",
        "        # Generate indexes of the batch\n",
        "        indexes = range(index*self.batch_size, (index+1)*self.batch_size)\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(indexes)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "    \n",
        "    def __data_generation(self, indexes):\n",
        "        \n",
        "        image_data = np.empty((self.batch_size, self.img_res, self.image_res, 3), dtype = float)\n",
        "        label_matrix = np.empty((self.batch_size, self.S, self.S, self.C + 5 * self.B), dtype = float)\n",
        "        \n",
        "        for index in indexes:\n",
        "          label_path = os.path.join(self.label_dir, self.annotations.iloc[index, 1])\n",
        "          boxes = []\n",
        "          with open(label_path) as f:\n",
        "              for label in f.readlines():\n",
        "                  class_label, x, y, width, height = [\n",
        "                    float(x) if float(x) != int(float(x)) else int(x)\n",
        "                    for x in label.replace(\"\\n\", \"\").split()\n",
        "                    ]\n",
        "\n",
        "                  boxes.append([class_label, x, y, width, height])\n",
        "\n",
        "          img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0])\n",
        "          image = np.asarray(Image.open(img_path))\n",
        "          image_data[index, :, :, :] = image\n",
        "\n",
        "        # Convert To Cells\n",
        "          label_matrix[index, :, :, :] = np.zeros((self.S, self.S, self.C + 5 * self.B), dtype = float)\n",
        "        \n",
        "          for box in boxes:\n",
        "\n",
        "            class_label, x, y, width, height = box\n",
        "            class_label = int(class_label)\n",
        "\n",
        "            # i,j represents the cell row and cell column\n",
        "            i, j = int(self.S * y), int(self.S * x)\n",
        "            x_cell, y_cell = self.S * x - j, self.S * y - i\n",
        "\n",
        "            \"\"\"\n",
        "            Calculating the width and height of cell of bounding box,\n",
        "            relative to the cell is done by the following, with\n",
        "            width as the example:\n",
        "            \n",
        "            width_pixels = (width*self.image_width)\n",
        "            cell_pixels = (self.image_width)\n",
        "            \n",
        "            Then to find the width relative to the cell is simply:\n",
        "            width_pixels/cell_pixels, simplification leads to the\n",
        "            formulas below.\n",
        "            \"\"\"\n",
        "            width_cell, height_cell = (width * self.S, height * self.S)\n",
        "\n",
        "                  \n",
        "            # If no object already found for specific cell i,j\n",
        "            # Note: This means we restrict to ONE object\n",
        "            # per cell!\n",
        "            if label_matrix[index, i, j, 20] == 0.0:\n",
        "\n",
        "                # Set that there exists an object\n",
        "              label_matrix[index, i, j, 20] = 1.0\n",
        "\n",
        "                # Box coordinates\n",
        "              box_coordinates = np.array([x_cell, y_cell, width_cell, height_cell], dtype = float)\n",
        "\n",
        "              label_matrix[index, i, j, 21:25] = box_coordinates\n",
        "\n",
        "                # Set one hot encoding for class_label\n",
        "              label_matrix[index, i, j, class_label] = 1.0\n",
        "\n",
        "\n",
        "        return image_data, label_matrix #(N, H, W, C) and (N, S, S, 30)"
      ],
      "metadata": {
        "id": "1oJTbRtHgq92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traingen = CustomDataGenerator(csv_file, \n",
        "                         img_dir, \n",
        "                         label_dir, \n",
        "                         img_res, \n",
        "                         batch_size = 32, \n",
        "                         splitcell_size = 7, \n",
        "                         num_bbox = 2, \n",
        "                         num_classes = 20)\n",
        "\n",
        "valgen = CustomDataGenerator(csv_file, \n",
        "                         img_dir, \n",
        "                         label_dir, \n",
        "                         img_res, \n",
        "                         batch_size = 32, \n",
        "                         splitcell_size = 7, \n",
        "                         num_bbox = 2, \n",
        "                         num_classes = 20)"
      ],
      "metadata": {
        "id": "CJbyrdPFmkoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "YLQyx9D3Jir5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo.compile(\n",
        "    optimizer=\"adam\", \n",
        "    loss=yolo_loss)"
      ],
      "metadata": {
        "id": "i8h3w-YDLnNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"MODEL_CKPT.h5\", save_best_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "E9j27YOcMLtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100"
      ],
      "metadata": {
        "id": "ZpM2ijcHMlVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = yolo.fit(traingen, \n",
        "                    epochs=EPOCHS, \n",
        "                    validation_data=valgen, \n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "UWYx3HokJiE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the Model"
      ],
      "metadata": {
        "id": "1lGwuv-YaHDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches"
      ],
      "metadata": {
        "id": "Nb9UddHxiw2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YoloEval():\n",
        "  def __init__(self, model, generator, classes):\n",
        "    self.model = model()\n",
        "    self.gen = generator()\n",
        "    self.batch_size = self.gen.batch_size\n",
        "\n",
        "    self.X, self.y = self.gen[batch]\n",
        "\n",
        "    self.image = self.X[idx]\n",
        "    self.image_as_single_batch = np.expand_dims(self.image, 0)\n",
        "\n",
        "    self.predictions = self.model(self.image_as_single_batch)\n",
        "    self.classes = classes\n",
        "\n",
        "  \n",
        "  def convert_cellboxes(self, predictions, S=7):\n",
        "    \"\"\"\n",
        "    Converts bounding boxes output from Yolo with\n",
        "    an image split size of S into entire image ratios\n",
        "    rather than relative to cell ratios.\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size = predictions.shape[0]\n",
        "    bboxes1 = predictions[..., 21:25]\n",
        "    bboxes2 = predictions[..., 26:30]\n",
        "\n",
        "    scores = tf.concat([tf.expand_dims(predictions[..., 20], 0), tf.expand_dims(predictions[..., 25], 0)], axis = 0)\n",
        "\n",
        "    bestbox = tf.expand_dims(tf.math.argmax(scores, axis=0), -1)\n",
        "    bestbox = tf.cast(bestbox, tf.float32)\n",
        "    \n",
        "    best_boxes = bboxes1 * (1 - bestbox) + bestbox * bboxes2\n",
        "    \n",
        "    cell_indices = tf.expand_dims(tf.tile(tf.constant([[[0,1,2,3,4,5,6]]], dtype = tf.float32), tf.constant([32, 7 , 1])), -1)\n",
        "   \n",
        "    x = (1 / S) * (best_boxes[..., :1] + cell_indices)\n",
        "    y = (1 / S) * (best_boxes[..., 1:2] + layers.Permute((2, 1, 3))(cell_indices))\n",
        "    w_y = (1 / S)* (best_boxes[..., 2:4])\n",
        "    \n",
        "    \n",
        "    converted_bboxes = tf.concat([x, y, w_y], axis = -1)\n",
        "    \n",
        "    predicted_class = tf.expand_dims(tf.math.argmax(predictions[..., :20], axis = -1), -1)\n",
        "    predicted_class = tf.cast(predicted_class, tf.float32)\n",
        "    \n",
        "    best_confidence = tf.expand_dims(tf.math.maximum(predictions[..., 20], predictions[..., 25]), -1)\n",
        "\n",
        "    converted_preds = tf.concat([predicted_class, best_confidence, converted_bboxes], axis = -1)\n",
        "\n",
        "    return converted_preds \n",
        "\n",
        "  def cellboxes_to_boxes(self, predictions, S=7):\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "        Converts cell relative bounding boxes output from Yolo with\n",
        "        an image split size of S into bounding boxes with entire image ratio for plotting. \n",
        "    \"\"\"\n",
        "\n",
        "    converted_pred = tf.reshape(self.convert_cellboxes(predictions), (predictions.shape[0], S * S, -1))\n",
        "    all_bboxes = []\n",
        "\n",
        "    for ex_idx in range(out.shape[0]):\n",
        "      bboxes = []\n",
        "\n",
        "      for bbox_idx in range(S * S):\n",
        "        bboxes.append([x.numpy().tolist() for x in converted_pred[ex_idx, bbox_idx, :]])\n",
        "      all_bboxes.append(bboxes)\n",
        "\n",
        "    return all_bboxes  \n",
        "  \n",
        "  \n",
        "    # All_bboxes is of shape [image_example_index, bbox_index, [class_predction, confidence, x_mid, y_mid, width, height]]\n",
        "\n",
        "    # Implies each image_example containa multiple bboxes, with each bbox having their coordinates, class_prediction and confidence in the array     \n",
        "\n",
        "  def plot_image(self, batch, idx):\n",
        "    \n",
        "    \"\"\"Plots predicted bounding boxes on the image\n",
        "      \n",
        "      Image : Standard RGB\n",
        "\n",
        "      Boxes = [box_index, [class_prediction, confidence, x_mid, y_mid, width, height]]\n",
        "\n",
        "      Classes = [\"class_1\", \"class_2\".......num_classes]\n",
        "\n",
        "    \"\"\"\n",
        "    if not batch < len(self.generator):\n",
        "      raise IndexError(\"Given batch index is out of bounds of Generator.\")\n",
        "      \n",
        "    if not idx < self.batch_size:\n",
        "      raise IndexError(\"Given sample index is out of bounds of Batch Size.\")\n",
        "\n",
        "    X, y = self.gen[batch]\n",
        "\n",
        "    im = self.X[idx]\n",
        "    im_as_single_batch = np.expand_dims(im, 0)\n",
        "\n",
        "    predictions = self.model(im_as_single_batch)\n",
        "    boxes = self.cellboxes_to_boxes(predictions)\n",
        "\n",
        "    height, width, _ = im.shape\n",
        "\n",
        "    # Create figure and axes\n",
        "    fig, ax = plt.subplots(1)\n",
        "    # Display the image\n",
        "    ax.imshow(im)\n",
        "\n",
        "    # Create a Rectangle patch\n",
        "    for box in boxes:\n",
        "        box = box[2:]\n",
        "        # box[0] is class, box[1] is confidence\n",
        "        # box[2] is x midpoint, box[3] is y midpoint\n",
        "        # box[4] is width, box[5] is height\n",
        "        assert len(box) == 6, \"Got more values than in class, prob, x, y, w, h, in a box!\"\n",
        "        \n",
        "        pred_class = self.classes[int(box[0])]\n",
        "        confidence = box[1]*100\n",
        "        upper_left_x = box[2] - box[4] / 2\n",
        "        upper_left_y = box[3] - box[5] / 2\n",
        "        rect = patches.Rectangle(\n",
        "            (upper_left_x * width, upper_left_y * height),\n",
        "            box[4] * width,\n",
        "            box[5] * height,\n",
        "            linewidth=1,\n",
        "            edgecolor=\"r\",\n",
        "            facecolor=\"none\",\n",
        "        )\n",
        "        # Add the patch to the Axes\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(upper_left_x, upper_left_y, f'Predicted Class : {pred_class}\\n Confidence: {confidence} %', \n",
        "                transform = ax.transAxes, fontsize=14, color='green')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "82cq0Wg8BC_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [f\"class_{x}\" for x in range(20)]"
      ],
      "metadata": {
        "id": "PBQFMSI4ICdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_eval = YoloEval(model = yolo, generator = valgen, classes = classes)"
      ],
      "metadata": {
        "id": "300LK35xH-F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_eval.plot_image(batch_idx, sample_idx)"
      ],
      "metadata": {
        "id": "WWH_Zu-5JBid"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}